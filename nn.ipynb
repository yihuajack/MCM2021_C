{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "from PIL import Image \n",
    "from pylab import *\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_imlist(path): \n",
    "    return [os.path.join(path,f) for f in os.listdir(path) if (f.endswith('.jpg') or f.endswith('.png') or f.endswith('.gif'))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "## img_list = get_imlist(\"F:\\\\SP2021\\\\MCM\\MCM_C\\\\2021MCM_ProblemC_Files\\\\2021MCM_ProblemC_Files\")\n",
    "\n",
    "all_data = pd.read_csv('./data/Joined.csv', encoding='utf-8', index_col='Detection Date')\n",
    "# all_data\n",
    "all_data.index = pd.to_datetime(all_data.index, errors='coerce')\n",
    "all_data = all_data.sort_values(by = 'Detection Date', ascending=True)\n",
    "\n",
    "## positive\n",
    "data_positive = all_data[(all_data['Lab Status'] == \"Positive ID\")]\n",
    "positive_img_list = []\n",
    "x_s, y_s = 250, 250\n",
    "for file in data_positive['FileName']:\n",
    "    im = Image.open(os.path.join(\"F:\\\\SP2021\\\\MCM\\MCM_C\\\\2021MCM_ProblemC_Files\\\\2021MCM_ProblemC_Files\", file))\n",
    "    rgb = im.split()\n",
    "    red, green, blue = rgb[0], rgb[1], rgb[2]\n",
    "    r, g, b = rgb[0].resize((x_s, y_s), Image.ANTIALIAS), rgb[1].resize((x_s, y_s), Image.ANTIALIAS), rgb[2].resize((x_s, y_s), Image.ANTIALIAS)\n",
    "    new_image = Image.merge(\"RGB\", (r, g, b))\n",
    "    positive_img_list.append(np.array(new_image))\n",
    "\n",
    "## negative\n",
    "data_negative = all_data[(all_data['Lab Status'] == \"Negative ID\") & (all_data['FileType'] == 'image/jpg')]\n",
    "negative_img_list = []\n",
    "for file in data_negative['FileName']:\n",
    "    im = Image.open(os.path.join(\"F:\\\\SP2021\\\\MCM\\MCM_C\\\\2021MCM_ProblemC_Files\\\\2021MCM_ProblemC_Files\", file))\n",
    "    rgb = im.split()\n",
    "    red, green, blue = rgb[0], rgb[1], rgb[2]\n",
    "    r, g, b = rgb[0].resize((x_s, y_s)), rgb[1].resize((x_s, y_s)), rgb[2].resize((x_s, y_s))\n",
    "    new_image = Image.merge(\"RGB\", (r, g, b))\n",
    "    negative_img_list.append(np.array(new_image))"
   ]
  },
  {
   "source": [
    "Get train/test data Set"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "## https://blog.csdn.net/u013733326/article/details/79639509\n",
    "# train_set_x_orig , train_set_y , test_set_x_orig , test_set_y , classes\n",
    "positive_img_list_added = get_imlist('F:\\\\SP2021\\\\MCM2021\\\\MCM2021_C\\\\data\\\\RefImages')\n",
    "for file in positive_img_list_added:\n",
    "    im = Image.open(file)\n",
    "    rgb = im.split()\n",
    "    red, green, blue = rgb[0], rgb[1], rgb[2]\n",
    "    r, g, b = rgb[0].resize((x_s, y_s), Image.ANTIALIAS), rgb[1].resize((x_s, y_s), Image.ANTIALIAS), rgb[2].resize((x_s, y_s), Image.ANTIALIAS)\n",
    "    new_image = Image.merge(\"RGB\", (r, g, b))\n",
    "    positive_img_list.append(np.array(new_image))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "positive:211  negative:3019\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])"
      ]
     },
     "metadata": {},
     "execution_count": 122
    }
   ],
   "source": [
    "m_train_positive = len(positive_img_list)\n",
    "m_train_negative = len(negative_img_list)\n",
    "print('positive:' + str(m_train_positive) + '  negative:' + str(m_train_negative))\n",
    "\n",
    "train_set_x_orig = np.array(positive_img_list[0:200] + negative_img_list[0:500])\n",
    "train_set_y = np.array([[1 for i in range(200)] + [0 for i in range(500)]])\n",
    "train_set_y.reshape(1,700)\n",
    "\n",
    "test_set_x_orig = np.array(positive_img_list[201:] + negative_img_list[501:551])\n",
    "test_set_y = np.array([[1 for i in range(10)] + [0 for i in range(50)]])\n",
    "test_set_y.reshape(1,60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "训练集的数量: m_train = 700\n测试集的数量 : m_test = 60\n每张图片的宽/高 : num_px = 250\n每张图片的大小 : (250, 250, 3)\n训练集_图片的维数 : (700, 250, 250, 3)\n训练集_标签的维数 : (1, 700)\n测试集_图片的维数: (60, 250, 250, 3)\n测试集_标签的维数: (1, 60)\n"
     ]
    }
   ],
   "source": [
    "m_train = train_set_y.shape[1] #训练集里图片的数量。\n",
    "m_test = test_set_y.shape[1] #测试集里图片的数量。\n",
    "num_px = train_set_x_orig.shape[1] #训练、测试集里面的图片的宽度和高度（均为64x64）。\n",
    "\n",
    "#现在看一看我们加载的东西的具体情况\n",
    "print (\"训练集的数量: m_train = \" + str(m_train))\n",
    "print (\"测试集的数量 : m_test = \" + str(m_test))\n",
    "print (\"每张图片的宽/高 : num_px = \" + str(num_px))\n",
    "print (\"每张图片的大小 : (\" + str(num_px) + \", \" + str(num_px) + \", 3)\")\n",
    "print (\"训练集_图片的维数 : \" + str(train_set_x_orig.shape))\n",
    "print (\"训练集_标签的维数 : \" + str(train_set_y.shape))\n",
    "print (\"测试集_图片的维数: \" + str(test_set_x_orig.shape))\n",
    "print (\"测试集_标签的维数: \" + str(test_set_y.shape))\n",
    "\n",
    "# index = 6\n",
    "# plt.imshow(train_set_x_orig[index])\n",
    "print(\"y=\" + str(train_set_y[:,index]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_flatten = X.reshape(X.shape [0]，-1).T ＃X.T\n",
    "train_set_x_flatten  = train_set_x_orig.reshape(train_set_x_orig.shape[0],-1).T\n",
    "test_set_x_flatten = test_set_x_orig.reshape(test_set_x_orig.shape[0], -1).T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "训练集降维最后的维度： (187500, 700)\n训练集_标签的维数 : (1, 700)\n测试集降维之后的维度: (187500, 60)\n测试集_标签的维数 : (1, 60)\n"
     ]
    }
   ],
   "source": [
    "print (\"训练集降维最后的维度： \" + str(train_set_x_flatten.shape))\n",
    "print (\"训练集_标签的维数 : \" + str(train_set_y.shape))\n",
    "print (\"测试集降维之后的维度: \" + str(test_set_x_flatten.shape))\n",
    "print (\"测试集_标签的维数 : \" + str(test_set_y.shape))\n"
   ]
  },
  {
   "source": [
    "To represent a color image, red, green, and blue channels (RGB) must be specified for each pixel, so the pixel value is actually a vector of three digits in the range 0 to 255.A common preprocessing step in machine learning is to center and normalize the dataset, which means you can subtract the average of the entire NumPy array in each example, and then divide each example by the standard deviation of the entire NumPy array.But for the image dataset, it is simpler and more convenient to divide almost every row of the dataset by 255 (the maximum number of pixel channels). Since there is no data larger than 255 in RGB, we can safely divide by 255 to make the normalized data between 0 and 1. Now we can normalize our dataset:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set_x = train_set_x_flatten / 255\n",
    "test_set_x = test_set_x_flatten / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    s = 1 / (1 + np.exp(-z))\n",
    "    return s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_with_zeros(dim):\n",
    "    \"\"\"\n",
    "       return \n",
    "            w  - vector(dim，1)\n",
    "            b  - scalar\n",
    "    \"\"\"\n",
    "    w = np.zeros(shape = (dim,1))\n",
    "    b = 0\n",
    "    assert(w.shape == (dim, 1)) #w(dim,1)\n",
    "    assert(isinstance(b, float) or isinstance(b, int)) #b\n",
    "    return (w , b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "def propagate(w, b, X, Y):\n",
    "    #     w  - array(num_px * num_px * 3，1)\n",
    "    #     b  - scalar\n",
    "    #     X  - array(num_px * num_px * 3，700)\n",
    "    #     Y  - array(1, 700)\n",
    "\n",
    "    # return:\n",
    "    #     cost- cost function\n",
    "    #     dw  - gradient of w\n",
    "    #     db  - gradient of b\n",
    "    m = X.shape[1]\n",
    "    #forward propagation\n",
    "    A = sigmoid(np.dot(w.T, X) + b) \n",
    "    cost = (- 1 / m) * np.sum(Y * np.log(A) + (1 - Y) * (np.log(1 - A))) \n",
    "    #bp\n",
    "    dw = (1 / m) * np.dot(X, (A - Y).T) \n",
    "    db = (1 / m) * np.sum(A - Y) \n",
    "    assert(dw.shape == w.shape)\n",
    "    assert(db.dtype == float)\n",
    "    cost = np.squeeze(cost)\n",
    "    assert(cost.shape == ())\n",
    "    grads = {\"dw\": dw, \"db\": db}\n",
    "    return (grads , cost)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "====================propagate====================\ndw = [[0.99993216]\n [1.99980262]]\ndb = 0.49993523062470574\ncost = 6.000064773192205\n"
     ]
    }
   ],
   "source": [
    "#test\n",
    "print(\"====================propagate====================\")\n",
    "w, b, X, Y = np.array([[1], [2]]), 2, np.array([[1,2], [3,4]]), np.array([[1, 0]])\n",
    "grads, cost = propagate(w, b, X, Y)\n",
    "print (\"dw = \" + str(grads[\"dw\"]))\n",
    "print (\"db = \" + str(grads[\"db\"]))\n",
    "print (\"cost = \" + str(cost))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize(w , b , X , Y , num_iterations , learning_rate , print_cost = False):\n",
    "    \"\"\"\n",
    "    GRADIENT DECENT\n",
    "    parameter\n",
    "        w  - (num_px * num_px * 3, 1)\n",
    "        b  - scalar\n",
    "        X  - (num_px * num_px * 3, 700)\n",
    "        Y  - [1/0]\n",
    "        num_iterations \n",
    "        learning_rate \n",
    "        print_cost \n",
    "    \n",
    "    return :\n",
    "        params  - {w, b}\n",
    "        grads  - {dw, db}\n",
    "        cost\n",
    "    \"\"\"\n",
    "    costs = []\n",
    "\n",
    "    for i in range(num_iterations):\n",
    "        \n",
    "        grads, cost = propagate(w, b, X, Y)\n",
    "        \n",
    "        dw = grads[\"dw\"]\n",
    "        db = grads[\"db\"]\n",
    "        \n",
    "        w = w - learning_rate * dw\n",
    "        b = b - learning_rate * db\n",
    "\n",
    "        if i % 100 == 0:\n",
    "            costs.append(cost)\n",
    "        if (print_cost) and (i % 100 == 0):\n",
    "            print(\"epoch time: %i, error: %f\" % (i,cost))\n",
    "        \n",
    "    params  = {\n",
    "                \"w\" : w,\n",
    "                \"b\" : b }\n",
    "    grads = {\n",
    "            \"dw\": dw,\n",
    "            \"db\": db } \n",
    "    return (params , grads , costs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "====================test optimize====================\nw = [[0.1124579 ]\n [0.23106775]]\nb = 1.5593049248448891\ndw = [[0.90158428]\n [1.76250842]]\ndb = 0.4304620716786828\n"
     ]
    }
   ],
   "source": [
    "#test optimize\n",
    "print(\"====================test optimize====================\")\n",
    "w, b, X, Y = np.array([[1], [2]]), 2, np.array([[1,2], [3,4]]), np.array([[1, 0]])\n",
    "params , grads , costs = optimize(w , b , X , Y , num_iterations=100 , learning_rate = 0.009 , print_cost = False)\n",
    "print (\"w = \" + str(params[\"w\"]))\n",
    "print (\"b = \" + str(params[\"b\"]))\n",
    "print (\"dw = \" + str(grads[\"dw\"]))\n",
    "print (\"db = \" + str(grads[\"db\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(w , b , X ):   \n",
    "    m  = X.shape[1] #图片的数量\n",
    "    Y_prediction = np.zeros((1,m)) \n",
    "    w = w.reshape(X.shape[0],1)\n",
    "    \n",
    "    #计预测猫在图片中出现的概率\n",
    "    A = sigmoid(np.dot(w.T , X) + b)\n",
    "    for i in range(A.shape[1]):\n",
    "        #将概率a [0，i]转换为实际预测p [0，i]\n",
    "        Y_prediction[0,i] = 1 if A[0,i] > 0.5 else 0\n",
    "    #使用断言\n",
    "    assert(Y_prediction.shape == (1,m))\n",
    "    \n",
    "    return Y_prediction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "====================test predict====================\npredictions = [[1. 1.]]\n"
     ]
    }
   ],
   "source": [
    "#test predict\n",
    "print(\"====================test predict====================\")\n",
    "w, b, X, Y = np.array([[1], [2]]), 2, np.array([[1,2], [3,4]]), np.array([[1, 0]])\n",
    "print(\"predictions = \" + str(predict(w, b, X)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(X_train , Y_train , X_test , Y_test , num_iterations = 2000 , learning_rate = 0.5 , print_cost = False):\n",
    "    w , b = initialize_with_zeros(X_train.shape[0])\n",
    "    \n",
    "    parameters , grads , costs = optimize(w , b , X_train , Y_train,num_iterations , learning_rate , print_cost)\n",
    "    \n",
    "    #从字典“参数”中检索参数w和b\n",
    "    w , b = parameters[\"w\"] , parameters[\"b\"]\n",
    "    \n",
    "    #预测测试/训练集的例子\n",
    "    Y_prediction_test = predict(w , b, X_test)\n",
    "    Y_prediction_train = predict(w , b, X_train)\n",
    "    \n",
    "    #打印训练后的准确性\n",
    "    print(\"训练集准确性：\"  , format(100 - np.mean(np.abs(Y_prediction_train - Y_train)) * 100) ,\"%\")\n",
    "    print(\"测试集准确性：\"  , format(100 - np.mean(np.abs(Y_prediction_test - Y_test)) * 100) ,\"%\")\n",
    "    \n",
    "    d = {\n",
    "            \"costs\" : costs,\n",
    "            \"Y_prediction_test\" : Y_prediction_test,\n",
    "            \"Y_prediciton_train\" : Y_prediction_train,\n",
    "            \"w\" : w,\n",
    "            \"b\" : b,\n",
    "            \"learning_rate\" : learning_rate,\n",
    "            \"num_iterations\" : num_iterations }\n",
    "    return d\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "====================test model====================\n",
      "epoch time: 0, error: 0.693147\n",
      "epoch time: 100, error: nan\n",
      "epoch time: 200, error: nan\n",
      "epoch time: 300, error: nan\n",
      "epoch time: 400, error: nan\n",
      "epoch time: 500, error: nan\n",
      "epoch time: 600, error: nan\n",
      "epoch time: 700, error: nan\n",
      "epoch time: 800, error: nan\n",
      "epoch time: 900, error: nan\n",
      "epoch time: 1000, error: nan\n",
      "epoch time: 1100, error: nan\n",
      "epoch time: 1200, error: nan\n",
      "epoch time: 1300, error: nan\n",
      "epoch time: 1400, error: nan\n",
      "epoch time: 1500, error: nan\n",
      "epoch time: 1600, error: nan\n",
      "epoch time: 1700, error: nan\n",
      "epoch time: 1800, error: nan\n",
      "epoch time: 1900, error: nan\n",
      "训练集准确性： 100.0 %\n",
      "测试集准确性： 75.0 %\n"
     ]
    }
   ],
   "source": [
    "print(\"====================test model====================\")\n",
    "d = model(train_set_x, train_set_y, test_set_x, test_set_y, num_iterations = 2000, learning_rate = 0.005, print_cost = True)\n"
   ]
  }
 ]
}